{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5eb245c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook file is valid JSON!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"LightGBM_PUB.ipynb\", \"r\", encoding=\"utf-8\") as f:\n",
    "    try:\n",
    "        data = json.load(f)\n",
    "        print(\"Notebook file is valid JSON!\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Notebook format error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd59abb6-9d34-42f2-adfa-6a75229e5913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA, NMF\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4eb8e955-d625-4a87-80ad-85b10e50455a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader\n",
    "csf_data = pd.read_csv(\"merged_csf_cross_sectional_call_rate_pau_data_0205.xls\", low_memory=False)\n",
    "plasma_data = pd.read_csv(\"merged_plasma_cross_sectional_call_rate_data_0130.xls\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ac5e08d-cdb0-4b77-9786-8ab2bc08383a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Status_at_draw_mapping\n",
       "CO     1282\n",
       "AD      865\n",
       "PD      687\n",
       "DLB     122\n",
       "FTD      44\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plasma_data['Status_at_draw_mapping'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bc7ea48-19ae-4754-8693-4bdcd146992d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plasma_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97350383-561f-409e-9ddc-98e24929eb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "csf_significant_rows = pd.read_csv(\"csf_significant_rows_0205.csv\")\n",
    "plasma_significant_rows = pd.read_csv(\"plasma_significant_rows_0203.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6972e57-b1aa-4e4c-b3c9-42205bdbd4e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb450d88-fe3f-45fa-baba-c88de08255a4",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f8eb5f57-5f0b-48d5-9399-fd7fb094e472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4750, 6648)\n"
     ]
    }
   ],
   "source": [
    "data = plasma_data.copy()\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a646bc51-d49b-41ea-aac5-d7da36877e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6607"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_columns = [col for col in plasma_data.columns if col.startswith('X')]\n",
    "len(x_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "42a18fc8-f5f0-45e7-8083-19eeb9b951ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3607\n"
     ]
    }
   ],
   "source": [
    "protein_list = list(plasma_significant_rows['Analytes'])\n",
    "print(len(protein_list))\n",
    "# protein_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "38712f18-0f9b-4335-9941-020307c25665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Status_at_draw_mapping\n",
       "CO     1282\n",
       "AD      865\n",
       "PD      687\n",
       "DLB     122\n",
       "FTD      44\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Status_at_draw_mapping'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5a2fc22d-e314-4215-b8b9-bbd50d344d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Project_y\n",
       "MAP         3110\n",
       "PD          1012\n",
       "Stanford     628\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Project_y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "97ed7d7d-424a-4641-8863-aee23d715c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 6648)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statuses_to_keep = ['CO', 'AD', 'PD', 'FTD', 'DLB']\n",
    "\n",
    "filtered_data = data[data['Status_at_draw_mapping'].isin(statuses_to_keep)]\n",
    " \n",
    "filtered_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9e175ef6-d921-4f24-bcfb-e6d2f0e8ab3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Project_y\n",
       "MAP         2184\n",
       "PD           689\n",
       "Stanford     127\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data['Project_y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f2554045-22e9-46a8-964e-df741a0f1448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Status_at_draw_mapping\n",
       "CO     1282\n",
       "AD      865\n",
       "PD      687\n",
       "DLB     122\n",
       "FTD      44\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data['Status_at_draw_mapping'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d56d5fbd-4733-45af-9541-bc15c5e35d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['UniquePhenoID', 'DrawDate', 'Project_x', 'Project_y', 'Age_at_draw', 'Sex', 'AT_class', 'PET_imaging', 'T1_pTau217', 'T2_pTau181', 'Status_at_draw_mapping', 'Status_at_draw', 'Final_Status']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3000, 3620)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data = filtered_data.rename(columns={'final_decision': 'PET_imaging'})\n",
    "\n",
    "columns_to_keep = ['UniquePhenoID', 'DrawDate', 'Project_x', 'Project_y', 'Age_at_draw', 'Sex', 'AT_class', 'PET_imaging', 'T1_pTau217',\n",
    "       'T2_pTau181', 'Status_at_draw_mapping', 'Status_at_draw', 'Final_Status']\n",
    "print(columns_to_keep)\n",
    "\n",
    "selected_protein_columns = [col for col in data.columns if col in protein_list]\n",
    "\n",
    "selected_columns = list(columns_to_keep) + selected_protein_columns\n",
    "\n",
    "selected_data = filtered_data[selected_columns]\n",
    "\n",
    "selected_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1c745c9b-cf81-436a-9659-80b059db5621",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\x.ying1\\AppData\\Local\\Temp\\ipykernel_26308\\3170815002.py:2: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  non_float_columns = selected_data.iloc[:,13:].applymap(lambda x: isinstance(x, (float, int))).all() == False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All columns are float type.\n"
     ]
    }
   ],
   "source": [
    "# Check which columns contain non-float values\n",
    "non_float_columns = selected_data.iloc[:,13:].applymap(lambda x: isinstance(x, (float, int))).all() == False\n",
    "non_float_columns_indices = non_float_columns[non_float_columns].index\n",
    "\n",
    "if not non_float_columns_indices.empty:\n",
    "    print(f\"Columns with non-float values: {list(non_float_columns_indices)}\")\n",
    "else:\n",
    "    print(\"All columns are float type.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "80786098-4f87-42cc-91fa-d67a3b99d9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of NA values in selected_data: 356254\n",
      "Columns with NA values and their counts:\n",
      "X10000.28    245\n",
      "X10001.7     125\n",
      "X10003.15    188\n",
      "X10006.25    160\n",
      "X10010.10    184\n",
      "            ... \n",
      "X9986.14      20\n",
      "X9989.12      76\n",
      "X9991.112    240\n",
      "X9993.11      87\n",
      "X9995.6      142\n",
      "Length: 3588, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for NA values in selected_data\n",
    "na_counts = selected_data.iloc[:,13:].isna().sum()\n",
    "\n",
    "# Get columns with NA values\n",
    "na_columns = na_counts[na_counts > 0]\n",
    "\n",
    "# Print the total number of NA values and columns with NA values\n",
    "total_na = na_counts.sum()\n",
    "print(f\"Total number of NA values in selected_data: {total_na}\")\n",
    "if not na_columns.empty:\n",
    "    print(\"Columns with NA values and their counts:\")\n",
    "    print(na_columns)\n",
    "else:\n",
    "    print(\"No NA values in selected_data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8c3a2c9c-e955-4866-b27a-4b4d38b3f285",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\x.ying1\\AppData\\Local\\Temp\\ipykernel_26308\\2335237837.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_data[num_cols] = (\n",
      "C:\\Users\\x.ying1\\AppData\\Local\\Temp\\ipykernel_26308\\2335237837.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_data[num_cols] = selected_data[num_cols].fillna(selected_data[num_cols].median())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of NA values in selected_data after filling: 0\n",
      "No NA values in selected_data after filling.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "def bootstrap_impute(series):\n",
    "    observed = series.dropna()\n",
    "    n_missing = series.isna().sum()\n",
    "    if n_missing > 0 and len(observed) > 0:\n",
    "        imputed_values = np.random.choice(observed, size=n_missing, replace=True)\n",
    "        series.loc[series.isna()] = imputed_values\n",
    "    return series\n",
    "\n",
    "num_cols = selected_data.columns[13:]\n",
    "\n",
    "selected_data[num_cols] = (\n",
    "    selected_data.groupby(\"Status_at_draw\", group_keys=False)[num_cols]\n",
    "    .apply(lambda g: g.apply(bootstrap_impute, axis=0))\n",
    ")\n",
    "\n",
    "selected_data[num_cols] = selected_data[num_cols].fillna(selected_data[num_cols].median())\n",
    "\n",
    "na_counts_after = selected_data[num_cols].isna().sum()\n",
    "total_na_after = na_counts_after.sum()\n",
    "print(f\"Total number of NA values in selected_data after filling: {total_na_after}\")\n",
    "\n",
    "if not na_counts_after[na_counts_after > 0].empty:\n",
    "    print(\"Columns with remaining NA values and their counts:\")\n",
    "    print(na_counts_after[na_counts_after > 0])\n",
    "else:\n",
    "    print(\"No NA values in selected_data after filling.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3eb458-d648-45db-bcb2-b5b673cbe830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d625b4a8-ec63-4dce-821f-28e1611d64cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4485b40-9423-4948-acba-61dc9d114f4b",
   "metadata": {},
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a7f0c660-1cef-4443-9d31-4bd028070c0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 3607)\n",
      "(3000, 3607)\n",
      "(3000, 400)\n",
      "[LightGBM] [Info] Total Bins 102000\n",
      "[LightGBM] [Info] Number of data points in the train set: 4483, number of used features: 400\n",
      "[LightGBM] [Info] Start training from score -1.610107\n",
      "[LightGBM] [Info] Start training from score -1.610107\n",
      "[LightGBM] [Info] Start training from score -1.608992\n",
      "[LightGBM] [Info] Start training from score -1.608992\n",
      "[LightGBM] [Info] Start training from score -1.608992\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Class Labels: ['AD' 'CO' 'DLB' 'FTD' 'PD']\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, f1_score, balanced_accuracy_score\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, VarianceThreshold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTETomek\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = selected_data.iloc[:, 13:]\n",
    "print(X.shape)\n",
    "\n",
    "y = selected_data['Status_at_draw_mapping']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "variance_filter = VarianceThreshold(threshold=0.01)\n",
    "X_filtered = variance_filter.fit_transform(X)\n",
    "print(X_filtered.shape)\n",
    "\n",
    "k_best_selector = SelectKBest(score_func=f_classif, k=min(400, X_filtered.shape[1]))\n",
    "X_selected = k_best_selector.fit_transform(X_filtered, y_encoded)\n",
    "print(X_selected.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y_encoded, test_size=0.3, random_state=42, stratify=y_encoded)\n",
    "\n",
    "smote_tomek = SMOTETomek(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote_tomek.fit_resample(X_train, y_train)\n",
    "\n",
    "lgbm_model = LGBMClassifier(\n",
    "    n_estimators=300, max_depth=20, learning_rate=0.05, random_state=42,\n",
    "    min_child_samples=10, min_split_gain=0.0, objective='multiclass', metric='multi_logloss',\n",
    "    force_col_wise=True\n",
    ")\n",
    "\n",
    "lgbm_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "class_labels = label_encoder.inverse_transform(np.unique(y_encoded))\n",
    "print(\"Class Labels:\", class_labels)\n",
    "\n",
    "# Prediction\n",
    "y_pred = lgbm_model.predict(X_test)\n",
    "y_pred_proba = lgbm_model.predict_proba(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "f1_macro = f1_score(y_test, y_pred, average=\"macro\")\n",
    "\n",
    "auc_ovr_weighted = roc_auc_score(y_test, y_pred_proba, multi_class=\"ovr\", average=\"weighted\")\n",
    "auc_ovr_macro = roc_auc_score(y_test, y_pred_proba, multi_class=\"ovr\", average=\"macro\")\n",
    "auc_ovo_weighted = roc_auc_score(y_test, y_pred_proba, multi_class=\"ovo\", average=\"weighted\")\n",
    "auc_ovo_macro = roc_auc_score(y_test, y_pred_proba, multi_class=\"ovo\", average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cf4e06c7-4bb8-4ddd-98fc-22d6abd9220b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 66.67%\n",
      "Balanced Accuracy: 40.34%\n",
      "Macro F1-score: 0.3972\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6303    0.6911    0.6593       259\n",
      "           1     0.6839    0.8260    0.7482       385\n",
      "           2     0.0000    0.0000    0.0000        37\n",
      "           3     0.0000    0.0000    0.0000        13\n",
      "           4     0.6867    0.5000    0.5787       206\n",
      "\n",
      "    accuracy                         0.6667       900\n",
      "   macro avg     0.4002    0.4034    0.3972       900\n",
      "weighted avg     0.6311    0.6667    0.6423       900\n",
      "\n",
      "OvR AUC Weighted: 0.8477\n",
      "OvR AUC Macro: 0.7633\n",
      "OvO AUC Weighted: 0.7645\n",
      "OvO AUC Macro: 0.7293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\x.ying1\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\x.ying1\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\x.ying1\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Balanced Accuracy: {balanced_acc * 100:.2f}%\")\n",
    "print(f\"Macro F1-score: {f1_macro:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, digits=4))\n",
    "print(f\"OvR AUC Weighted: {auc_ovr_weighted:.4f}\")\n",
    "print(f\"OvR AUC Macro: {auc_ovr_macro:.4f}\")\n",
    "print(f\"OvO AUC Weighted: {auc_ovo_weighted:.4f}\")\n",
    "print(f\"OvO AUC Macro: {auc_ovo_macro:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3349a71a-e96b-4d2d-8c98-c86d2965c943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and processing components saved in plasma_model_output\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "save_dir = \"plasma_model_output\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "model_path = os.path.join(save_dir, \"plasma_lgbm_model_700_0411.pkl\")\n",
    "joblib.dump(lgbm_model, model_path)\n",
    "\n",
    "# label_encoder_path = os.path.join(save_dir, \"label_encoder.pkl\")\n",
    "# joblib.dump(label_encoder, label_encoder_path)\n",
    "\n",
    "# variance_filter_path = os.path.join(save_dir, \"variance_filter.pkl\")\n",
    "# joblib.dump(variance_filter, variance_filter_path)\n",
    "\n",
    "# k_best_selector_path = os.path.join(save_dir, \"k_best_selector.pkl\")\n",
    "# joblib.dump(k_best_selector, k_best_selector_path)\n",
    "\n",
    "selected_feature_names = X.columns[variance_filter.get_support()][k_best_selector.get_support()]\n",
    "feature_names_path = os.path.join(save_dir, \"plasma_selected_features_700_0411.txt\")\n",
    "\n",
    "with open(feature_names_path, \"w\") as f:\n",
    "    for feature in selected_feature_names:\n",
    "        f.write(feature + \"\\n\")\n",
    "\n",
    "print(f\"Model and processing components saved in {save_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015127ab-b595-4a61-bee9-4b6631fcb5e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4573733-8331-42b4-bea8-28adcc7729ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
